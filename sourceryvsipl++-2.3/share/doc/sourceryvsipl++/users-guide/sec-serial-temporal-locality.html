<html><head><meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1"><title>7.2. Serial Optimization: Temporal Locality</title><link rel="stylesheet" href="cs.css" type="text/css"><meta name="generator" content="DocBook XSL Stylesheets V1.74.0"><link rel="home" href="index.html" title="Sourcery VSIPL++"><link rel="up" href="chap-serial.html" title="Chapter 7. Fast Convolution"><link rel="prev" href="chap-serial.html" title="Chapter 7. Fast Convolution"><link rel="next" href="sec-io-user-spec-storage.html" title="7.3. Performing I/O with User-Specified Storage"></head><body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF"><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">7.2. Serial Optimization: Temporal Locality</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="chap-serial.html">Prev</a> </td><th width="60%" align="center">Chapter 7. Fast Convolution</th><td width="20%" align="right"> <a accesskey="n" href="sec-io-user-spec-storage.html">Next</a></td></tr></table><hr></div><div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="sec-serial-temporal-locality"></a>7.2. Serial Optimization: Temporal Locality</h2></div></div></div><p>In this section, you will learn how to improve the performance of
    fast convolution by improving <em class="firstterm">temporal locality</em>,
    i.e., by making accesses to the same memory locations occur near the same
    time.</p><p>The code in <a class="xref" href="chap-serial.html#sec-serial-fastconv" title="7.1. Fast Convolution">Section 7.1, &#8220;Fast Convolution&#8221;</a> performs a FFT on
    each row of the matrix. Then, after all the rows have been processed, it
    multiplies each row of the matrix by the <code class="varname">replica</code>.
    Suppose that there are a large number of rows, so that
    <code class="varname">data</code> is too large to fit in cache. In that case, while
    the results of the first FFT will be in cache immediately after the FFT is
    complete, that data will likey have been purged from the cache by the time
    the vector-matrix multiply needs the data.</p><p>Explicitly iterating over the rows of the matrix (performing a
    forward FFT, elementwise multiplication, and an inverse FFT on each row
    before going on to the next one) will improve temporal locality. You can
    use this approach by using an explicit loop, rather than the implicit
    parallelism of <code class="function">Fftm</code> and <code class="function">vmmul</code>,
    to take better advantage of the cache.</p><p>You must make a few changes to the application in order to implement
    this approach. Because the application will be operating on only a single
    row at a time, <code class="function">Fftm</code> must be replaced with the simpler
    <code class="function">Fft</code>. Similarly, <code class="function">vmmul</code> must be
    replaced with <code class="function">*</code>, which performs element-wise
    multiplication of its operands. Finally, <code class="varname">tmp</code> can now be
    a vector, rather than a matrix. (As a consequence, in addition to being
    faster, this new version of the application will require less memory.)
    Here is the revised program:</p><pre class="programlisting">// Create the data cube.
Matrix&lt;value_type&gt; data(npulse, nrange);
Vector&lt;value_type&gt; tmp(nrange);
// tmp is now a vector
// Create the pulse replica
Vector&lt;value_type&gt; replica(nrange);
// Define the FFT typedefs.
typedef Fft&lt;const_Vector,
            value_type, value_type, fft_fwd, by_reference&gt;
  for_fft_type;
typedef Fft&lt;const_Vector, value_type, value_type, fft_inv, by_reference&gt;
  inv_fft_type;
// Create the FFT objects.
for_fft_type for_fft(Domain&lt;1&gt;(nrange), 1.0);
inv_fft_type inv_fft(Domain&lt;1&gt;(nrange), 1.0/(nrange));
// Initialize data to zero
data = value_type();
replica = value_type();
// Before fast convolution, convert the replica into the
// frequency domain
for_fft(replica);
// Perform fast convolution:
for (index_type r=0; r &lt; nrange; ++r)
{
  for_fft(data.row(r), tmp);
  tmp *= replica;
  inv_fft(tmp, data.row(r));
}</pre><p>The following graph shows that the new "interleaved" formulation is
    faster than the original "phased" approach for large data sets. For
    smaller data sets (where all of the data fits in the cache anyhow), the
    original method is faster because performing all of the FFTs at once is
    faster than performing them one by one.</p><div class="mediaobject" align="center"><img src="images/par/fastconv-cache.png" align="middle"></div></div><div class="navfooter"><hr><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="chap-serial.html">Prev</a> </td><td width="20%" align="center"><a accesskey="u" href="chap-serial.html">Up</a></td><td width="40%" align="right"> <a accesskey="n" href="sec-io-user-spec-storage.html">Next</a></td></tr><tr><td width="40%" align="left" valign="top">Chapter 7. Fast Convolution </td><td width="20%" align="center"><a accesskey="h" href="index.html">Home</a></td><td width="40%" align="right" valign="top"> 7.3. Performing I/O with User-Specified Storage</td></tr></table></div></body></html>
