<html><head><meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1"><title>Chapter 8. Parallel Fast Convolution</title><link rel="stylesheet" href="cs.css" type="text/css"><meta name="generator" content="DocBook XSL Stylesheets V1.74.0"><meta name="description" content="This chapter describes how to create and run parallel VSIPL++ programs with Sourcery VSIPL++. You can modify the programs to develop your own parallel applications."><link rel="home" href="index.html" title="Sourcery VSIPL++"><link rel="up" href="pt02.html" title="Part II. Example Application"><link rel="prev" href="sec-io-extdata.html" title="7.4. Performing I/O with External Data Access"><link rel="next" href="ch08s02.html" title="8.2. Improving Parallel Temporal Locality"></head><body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF"><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">Chapter 8. Parallel Fast Convolution</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="sec-io-extdata.html">Prev</a> </td><th width="60%" align="center">Part II. Example Application</th><td width="20%" align="right"> <a accesskey="n" href="ch08s02.html">Next</a></td></tr></table><hr></div><div class="chapter" lang="en"><div class="titlepage"><div><div><h2 class="title"><a name="chap-parallel"></a>Chapter 8. Parallel Fast Convolution</h2></div><div><div class="abstract"><p class="title"><b>Abstract</b></p><p>This chapter describes how to create and run parallel VSIPL++
      programs with Sourcery VSIPL++. You can modify the programs to develop
      your own parallel applications.</p></div></div></div></div><div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="section"><a href="chap-parallel.html#sec-parallel-fastconv">8.1. Parallel Fast Convolution</a></span></dt><dt><span class="section"><a href="ch08s02.html">8.2. Improving Parallel Temporal Locality</a></span></dt><dt><span class="section"><a href="sec-parallel-io.html">8.3. Performing I/O</a></span></dt></dl></div><p>This chapter explains how to use Sourcery VSIPL++ to perform parallel
  computations. You will see how to transform the fast convolution program
  from the previous chapter to run in parallel. First you will convert the
  <code class="function">Fftm</code> based version. Then you will convert the improved
  cache locality version. Finally, you will learn how to handle input and
  output when working in parallel.</p><div class="section" lang="en"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="sec-parallel-fastconv"></a>8.1. Parallel Fast Convolution</h2></div></div></div><p>The first fast convolution program in the previous chapter makes use
    of two implicitly parallel operators: <code class="function">Fftm</code> and
    <code class="function">vmmul</code>. These operators are implicitly parallel in the
    sense that they process each row of the matrix independently. If you had
    enough processors, you could put each row on a separate processor and then
    perform the entire computation in parallel.</p><p>In the VSIPL++ API, you have explicit control of the number of
    processors used for a computation. Since the default is to use just a
    single processor, the program in <a class="xref" href="chap-serial.html#sec-serial-fastconv" title="7.1. Fast Convolution">Section 7.1, &#8220;Fast Convolution&#8221;</a>
    will not run in parallel, even on a multi-processor system. This section
    will show you how to use <em class="firstterm">maps</em> to take advantage of
    multiple processors. Using a map tells Sourcery VSIPL++ to distribute a
    single block of data across multiple processors. Then, Sourcery VSIPL++
    will automatically move data between processors as necessary.</p><p>The VSIPL++ API uses the Single-Program Multiple-Data (SPMD) model
    for parallelism. In this model, every processor runs the same program, but
    operates on different sets of data. For example, in the fast convolution
    example, multiple processors perform FFTs at the same time, but each
    processor handles different rows in the matrix.</p><p>Every map has both compile-time and run-time properties. At
    compile-time, you specify the <em class="firstterm">distribution</em> that
    will be applied to each dimension. In this example, you will use a
    <em class="firstterm">block distribution</em> to distribute the rows of the
    matrix. A block distribution divides a view into continguous chunks. For
    example, suppose that you have a 4-processor system. Since there are 64
    rows in the matrix <code class="varname">data</code>, there will be 16 rows on each
    processor. The block distribution will place the first 16 rows (rows 0
    through 15) on processor 0, the next 16 rows (rows 16 through 31) on
    processor 1, and so forth. You do not want to distribute the columns of
    the matrix at all, so you will use a <em class="firstterm">whole
    distribution</em> for the columns.</p><p>Although the distributions are selected at compile-time, the number
    of processors to use in each dimension is not specified until run-time. By
    specifying the number of processors at run-time, you can adapt your
    program to the configuration of the machine on which your application is
    running. The VSIPL++ API provides a <code class="function">num_processors</code>
    function to tell you the total number of processors available. Of course,
    since each row should be kept on a single processor, the number of
    processors used in the column dimension is just one. So, here is the code
    required to create the map:</p><pre class="programlisting"> typedef Map&lt;Block_dist, Whole_dist&gt; map_type;
 map_type map = map_type(/*rows=*/num_processors(),
                         /*columns=*/1);</pre><p>Next, you have to tell Sourcery VSIPL++ to use this map for the
    relevant views. Every view has an underlying <em class="firstterm">block</em>.
    The block indicates how the view's data is stored. Until this point, you
    have been using the default <code class="classname">Dense</code> block, which
    stores data in a continguous array on a single processor. Now, you want to
    use a continguous array on <span class="emphasis"><em>multiple</em></span> processors, so
    you must explicitly distribute the block. Then, when declaring views, you
    must explicitly indicate that the view should use the distributed
    block:</p><pre class="programlisting"> typedef Dense&lt;2, value_type, row2_type, map_type&gt;
    block_type;
 typedef Matrix&lt;value_type, block_type&gt; view_type;
 view_type data(npulse, nrange, map);
 view_type tmp(npulse, nrange, map);</pre><p>Performing the vector-matrix multiply requires a complete copy of
    <code class="varname">replica</code> on each processor. An ordinary map divides data
    among processors, but, here, the goal is to copy the same data to multiple
    processors. Sourcery VSIPL++ provides a special
    <code class="classname">Replicated_map</code> class to use in this situation. So,
    you should declare <code class="varname">replica</code> as follows:</p><pre class="programlisting"> Replicated_map&lt;1&gt; replica_map;
 typedef Dense&lt;1,
     value_type, row1_type, Replicated_map&lt;1&gt; &gt;
   replica_block_type;
 typedef Vector&lt;value_type, replica_block_type&gt;
   replica_view_type;
 replica_view_type replica(nrange, replica_map);</pre><p>Because the application already uses implicitly parallel operators,
    no further changes are required. The entire algorithm (i.e., the part of
    the code that performs FFTs and vector-matrix multiplication) remains
    unchanged.</p><p>The complete parallel program is:</p><pre class="programlisting">
      /***********************************************************************
  Included Files
***********************************************************************/

#include &lt;vsip/initfin.hpp&gt;
#include &lt;vsip/support.hpp&gt;
#include &lt;vsip/signal.hpp&gt;
#include &lt;vsip/math.hpp&gt;
#include &lt;vsip/map.hpp&gt;

using namespace vsip;



/***********************************************************************
  Main Program
***********************************************************************/

int
main(int argc, char** argv)
{
  // Initialize the library.
  vsipl vpp(argc, argv);

  typedef complex&lt;float&gt; value_type;

  typedef Map&lt;Block_dist, Whole_dist&gt;               map_type;
  typedef Dense&lt;2, value_type, row2_type, map_type&gt; block_type;
  typedef Matrix&lt;value_type, block_type&gt;            view_type;

  typedef Dense&lt;1, value_type, row1_type, Replicated_map&lt;1&gt; &gt;
                                                    replica_block_type;
  typedef Vector&lt;value_type, replica_block_type&gt;    replica_view_type;

  // Parameters.
  length_type npulse = 64;	// number of pulses
  length_type nrange = 256;	// number of range cells

  // Maps.
  map_type          map = map_type(num_processors(), 1);
  Replicated_map&lt;1&gt; replica_map;

  // Views.
  replica_view_type replica(nrange, replica_map);
  view_type         data(npulse, nrange, map);
  view_type         tmp (npulse, nrange, map);

  // A forward Fft for computing the frequency-domain version of
  // the replica.
  typedef Fft&lt;const_Vector, value_type, value_type, fft_fwd, by_reference&gt;
		for_fft_type;
  for_fft_type  for_fft (Domain&lt;1&gt;(nrange), 1.0);

  // A forward Fftm for converting the time-domain data matrix to the
  // frequency domain.
  typedef Fftm&lt;value_type, value_type, row, fft_fwd, by_reference&gt;
	  	for_fftm_type;
  for_fftm_type for_fftm(Domain&lt;2&gt;(npulse, nrange), 1.0);

  // An inverse Fftm for converting the frequency-domain data back to
  // the time-domain.
  typedef Fftm&lt;value_type, value_type, row, fft_inv, by_reference&gt;
	  	inv_fftm_type;
  inv_fftm_type inv_fftm(Domain&lt;2&gt;(npulse, nrange), 1.0/(nrange));

  // Initialize data to zero.
  data    = value_type();
  replica = value_type();

  // Before fast convolution, convert the replica to the the
  // frequency domain
  for_fft(replica);


  // Perform fast convolution:

  // Convert to the frequency domain.
  for_fftm(data, tmp);

  // Perform element-wise multiply for each pulse.
  tmp = vmmul&lt;0&gt;(replica, tmp);

  // Convert back to the time domain.
  inv_fftm(tmp, data);
}

    </pre><p>The following graph shows the parallel speedup of the fast
    convolution program from 1 to 32 processors using a 3.0 GHz Pentium
    cluster system. As you can see, increasing the number of processors also
    increases the performance of the program.</p><div class="mediaobject" align="center"><img src="images/par/fastconv-speedup.png" align="middle"></div></div></div><div class="navfooter"><hr><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="sec-io-extdata.html">Prev</a> </td><td width="20%" align="center"><a accesskey="u" href="pt02.html">Up</a></td><td width="40%" align="right"> <a accesskey="n" href="ch08s02.html">Next</a></td></tr><tr><td width="40%" align="left" valign="top">7.4. Performing I/O with External Data Access </td><td width="20%" align="center"><a accesskey="h" href="index.html">Home</a></td><td width="40%" align="right" valign="top"> 8.2. Improving Parallel Temporal Locality</td></tr></table></div></body></html>
